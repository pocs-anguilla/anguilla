{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loaded-prerequisite",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we provide an introduction to setting up an instance of the MO-CMA-ES optimizer implementation\n",
    "available in the library and how to optimize a function using the two available interfaces.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* Basic setup\n",
    "* Instantiating a benchmark function\n",
    "* Instantiating the MOCMA optimizer\n",
    "* The `fmin` interface\n",
    "* The `ask` and `tell` interface\n",
    "* Using a custom function\n",
    "* References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-moisture",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-excuse",
   "metadata": {},
   "source": [
    "To install the library, we can use either `PyPI` or `Conda`:\n",
    "\n",
    "````bash\n",
    "    # Note this is an alternative to the official repository.\n",
    "    # It will be uploaded to the official PyPI repository.\n",
    "    pip install -i https://test.pypi.org/simple/ anguilla \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-moment",
   "metadata": {},
   "source": [
    "We then import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from anguilla.fitness import benchmark\n",
    "from anguilla.optimizers.mocma import MOCMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-agent",
   "metadata": {},
   "source": [
    "We set up a seed for reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "speaking-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 54545\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-bennett",
   "metadata": {},
   "source": [
    "## Instantiating a benchmark function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-animal",
   "metadata": {},
   "source": [
    "To run the optimizer we need a function to minimize. You probably want to optimize your own custom function. Here we will use a benchmark function from the implementations available in the library. However, we will also cover how to use the optimizer with custom functions.\n",
    "\n",
    "The library provides implementations of functions from various benchmarks used in real-valued multi-objective optimization (MOO).\n",
    "\n",
    "For this tutorial we will be using the DTLZ1$: \\mathbb{R}^{30} \\mapsto \\mathbb{R}^3$ benchmark function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "respective-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = 30\n",
    "n_objectives = 3\n",
    "fn = benchmark.DTLZ1(n_dimensions, n_objectives, rng=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-butter",
   "metadata": {},
   "source": [
    "## Instantiating the MOCMA optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-central",
   "metadata": {},
   "source": [
    "### Parents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-preview",
   "metadata": {},
   "source": [
    "The optimizer infers the number of *parents*, *dimensions* and *objectives*\n",
    "from the initial `parent_points` and `parent_fitness` arrays we pass to its constructor \n",
    "at instantiation.\n",
    "\n",
    "Note that we use `n_parents` to refer to $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contemporary-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parents = 100\n",
    "parent_points = fn.random_points(n_parents)\n",
    "parent_fitness = fn(parent_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-chapel",
   "metadata": {},
   "source": [
    "### Offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-tourism",
   "metadata": {},
   "source": [
    "We can omit providing a value for `n_offspring` when instantiating the optimizer.\n",
    "If `n_parents = 100`, then we would've be constructing an instance of $(100+100)$-MOCMA-ES \n",
    "If we'd like to use the steady-state variant, i.e $(100+1)-MOCMA-ES\n",
    "Then we need to set `n_offspring = 1`.\n",
    "\n",
    "Note that we use `n_offspring` to refer to $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "immune-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_offspring = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-promise",
   "metadata": {},
   "source": [
    "### Notion of success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-reception",
   "metadata": {},
   "source": [
    "The implementation supports both notions of success defined in the literature [1] [2].\n",
    "By default, if none is provided the optimizer uses the population-based notion of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fossil-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_notion = \"population\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-brown",
   "metadata": {},
   "source": [
    "### Creating the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-movement",
   "metadata": {},
   "source": [
    "We are ready to instantiate the MOCMA optimizer.\n",
    "Note that we need to specify at least one stopping condition,\n",
    "in this case we restrict the number of function evaluations by\n",
    "setting `max_evaluations=50000`. Other stopping conditions are\n",
    "`max_generations` and `target_indicator_value` (which requires providing a reference point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confused-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = MOCMA(parent_points,\n",
    "                  parent_fitness,\n",
    "                  n_offspring=n_offspring,\n",
    "                  success_notion=success_notion,\n",
    "                  max_evaluations=50000,\n",
    "                  rng=rng,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-fitting",
   "metadata": {},
   "source": [
    "To pass a reference point, we would've done the following:\n",
    "\n",
    "```python\n",
    "our_reference_point = None\n",
    "optimizer.indicator.reference = our_reference_point\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-requirement",
   "metadata": {},
   "source": [
    "## The `fmin` interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-makeup",
   "metadata": {},
   "source": [
    "Now, to optimize we can simply call the `fmin` method on the optimizer instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimizer.fmin(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-attraction",
   "metadata": {},
   "source": [
    "The optimizer returns an instance of `OptimizerResult`, which contains both the solution and the stopping conditions that were triggered.\n",
    "\n",
    "We can access the approximated Pareto set and front by:\n",
    "\n",
    "```python\n",
    "pareto_set = result.solution.points\n",
    "pareto_front = result.solution.fitness\n",
    "```\n",
    "\n",
    "We can inspect which condition(s) triggered the stop by:\n",
    "    \n",
    "```python\n",
    "result.stopping_conditions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-austin",
   "metadata": {},
   "source": [
    "## The `ask` and `tell` interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-plaza",
   "metadata": {},
   "source": [
    "An alternative interface, called the ask-and-tell interface, allows for decoupled\n",
    "execution between calls to the optimizer and the function.\n",
    "The `fmin` implementation uses the ask-and-tell interface under the hood.\n",
    "\n",
    "The `ask` method generates new search points (offspring) by using mutation\n",
    "operators on the parent population.\n",
    "\n",
    "The `tell` method is used to inform the optimizer about the fitness of these\n",
    "new points. It then performs environmental selection to produce the new parent population.\n",
    "\n",
    "When could we need to use this interface? Say, for example, that we want to checkpoint solutions every `5000` function evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not optimizer.stop.triggered:\n",
    "    points = optimizer.ask()\n",
    "    if fn.has_constraints:\n",
    "        fitness, penalized_fitness = fn.evaluate_with_penalty(points)\n",
    "        optimizer.tell(fitness, penalized_fitness)\n",
    "    else:\n",
    "        fitness = fn(points)\n",
    "        optimizer.tell(fitness)\n",
    "    if optimizer.evaluation_count % 5000 == 0:\n",
    "        # Access current Pareto front approximation\n",
    "        # and save it to a file\n",
    "        np.savetxt(f\"./output/fitness-{optimizer.evaluation_count}.csv\",\n",
    "                   optimizer.best.fitness,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-dylan",
   "metadata": {},
   "source": [
    "Note that we treated constrained functions a bit differently in the above example.\n",
    "This is because we should penalize search points that violate any constraints.\n",
    "To inform the optimizer about this, we can pass the penalized fitness.\n",
    "\n",
    "In the example above we've could also done:\n",
    "\n",
    "```python\n",
    "fitness = fn.evaluate_with_penalty(points)\n",
    "optimizer.tell(*fitness)\n",
    "```\n",
    "\n",
    "In addition, some functions are noisy. Usually, these functions are evaluated multiple times \n",
    "and an average of their fitness is reported to the optimizer. Naturally, this consumes more function evaluations\n",
    "from the budget we may've defined as a stopping condition. To inform the optimizer about this, we could do:\n",
    "\n",
    "```python\n",
    "    for i in range(n_repetitions):\n",
    "        fitness[i] = noisy_function(point)\n",
    "    optimizer.tell(np.average(fitness, axis=0), evaluation_count=n_evaluations) \n",
    "```\n",
    "\n",
    "Note, however, that you don't need to use the ask-and-tell interface to optimize noisy functions. You can abstract the noisy evaluation in a custom function and use `fmin` interface. In the next section, we will see how to define a custom function that the optimizer can minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-intent",
   "metadata": {},
   "source": [
    "After the optimizer finishes the optimization run, we can get the solution by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = optimizer.best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-desire",
   "metadata": {},
   "source": [
    "## Using a custom function\n",
    "\n",
    "Pending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-intermediate",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Pending"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
